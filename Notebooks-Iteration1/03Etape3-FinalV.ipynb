{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Etape 3 challenge is to create a new feature from our current data which might help our performance prediction.\n",
    "\n",
    "Most of this notebook is copied from etape 2. With a few modifications within the pipeline to create the new feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load clean trees data from saved pickle into the `trees` dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees = pd.read_pickle(\"../data/pickle/trees_first_clean.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "display first 5 lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   ELEM_POINT_ID      CODE SOUS_CATEGORIE SOUS_CATEGORIE_DESC CODE_PARENT  \\\n0          32215  ESP32919         ESP151     Arbre de voirie    ESP32840   \n1          32214  ESP32918         ESP151     Arbre de voirie    ESP32840   \n2          32213  ESP32917         ESP151     Arbre de voirie    ESP32840   \n3          32212  ESP32916         ESP151     Arbre de voirie    ESP32840   \n4          32211  ESP32915         ESP151     Arbre de voirie    ESP32840   \n\n                 CODE_PARENT_DESC  ADR_SECTEUR GENRE_BOTA     ESPECE  \\\n0  Crs Jaurès impair de PHD/ Lorr            2   Platanus   platanor   \n1  Crs Jaurès impair de PHD/ Lorr            2      Tilia  mongolica   \n2  Crs Jaurès impair de PHD/ Lorr            2      Malus    perpetu   \n3  Crs Jaurès impair de PHD/ Lorr            2   Platanus   platanor   \n4  Crs Jaurès impair de PHD/ Lorr            2      Tilia  mongolica   \n\n         VARIETE STADEDEDEVELOPPEMENT  ANNEEDEPLANTATION  \\\n0  Vallis clausa          Arbre jeune             2014.0   \n1            NaN          Arbre jeune             2014.0   \n2       Evereste          Arbre jeune             2014.0   \n3  Vallis clausa          Arbre jeune             2014.0   \n4            NaN          Arbre jeune             2014.0   \n\n               COLLECTIVITE   type  longitude   latitude  \n0  Grenoble Alpes Métropole  Point   5.719919  45.190237  \n1  Grenoble Alpes Métropole  Point   5.719994  45.190280  \n2  Grenoble Alpes Métropole  Point   5.720006  45.190322  \n3  Grenoble Alpes Métropole  Point   5.719959  45.190359  \n4  Grenoble Alpes Métropole  Point   5.720047  45.190442  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ELEM_POINT_ID</th>\n      <th>CODE</th>\n      <th>SOUS_CATEGORIE</th>\n      <th>SOUS_CATEGORIE_DESC</th>\n      <th>CODE_PARENT</th>\n      <th>CODE_PARENT_DESC</th>\n      <th>ADR_SECTEUR</th>\n      <th>GENRE_BOTA</th>\n      <th>ESPECE</th>\n      <th>VARIETE</th>\n      <th>STADEDEDEVELOPPEMENT</th>\n      <th>ANNEEDEPLANTATION</th>\n      <th>COLLECTIVITE</th>\n      <th>type</th>\n      <th>longitude</th>\n      <th>latitude</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>32215</td>\n      <td>ESP32919</td>\n      <td>ESP151</td>\n      <td>Arbre de voirie</td>\n      <td>ESP32840</td>\n      <td>Crs Jaurès impair de PHD/ Lorr</td>\n      <td>2</td>\n      <td>Platanus</td>\n      <td>platanor</td>\n      <td>Vallis clausa</td>\n      <td>Arbre jeune</td>\n      <td>2014.0</td>\n      <td>Grenoble Alpes Métropole</td>\n      <td>Point</td>\n      <td>5.719919</td>\n      <td>45.190237</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>32214</td>\n      <td>ESP32918</td>\n      <td>ESP151</td>\n      <td>Arbre de voirie</td>\n      <td>ESP32840</td>\n      <td>Crs Jaurès impair de PHD/ Lorr</td>\n      <td>2</td>\n      <td>Tilia</td>\n      <td>mongolica</td>\n      <td>NaN</td>\n      <td>Arbre jeune</td>\n      <td>2014.0</td>\n      <td>Grenoble Alpes Métropole</td>\n      <td>Point</td>\n      <td>5.719994</td>\n      <td>45.190280</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>32213</td>\n      <td>ESP32917</td>\n      <td>ESP151</td>\n      <td>Arbre de voirie</td>\n      <td>ESP32840</td>\n      <td>Crs Jaurès impair de PHD/ Lorr</td>\n      <td>2</td>\n      <td>Malus</td>\n      <td>perpetu</td>\n      <td>Evereste</td>\n      <td>Arbre jeune</td>\n      <td>2014.0</td>\n      <td>Grenoble Alpes Métropole</td>\n      <td>Point</td>\n      <td>5.720006</td>\n      <td>45.190322</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>32212</td>\n      <td>ESP32916</td>\n      <td>ESP151</td>\n      <td>Arbre de voirie</td>\n      <td>ESP32840</td>\n      <td>Crs Jaurès impair de PHD/ Lorr</td>\n      <td>2</td>\n      <td>Platanus</td>\n      <td>platanor</td>\n      <td>Vallis clausa</td>\n      <td>Arbre jeune</td>\n      <td>2014.0</td>\n      <td>Grenoble Alpes Métropole</td>\n      <td>Point</td>\n      <td>5.719959</td>\n      <td>45.190359</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>32211</td>\n      <td>ESP32915</td>\n      <td>ESP151</td>\n      <td>Arbre de voirie</td>\n      <td>ESP32840</td>\n      <td>Crs Jaurès impair de PHD/ Lorr</td>\n      <td>2</td>\n      <td>Tilia</td>\n      <td>mongolica</td>\n      <td>NaN</td>\n      <td>Arbre jeune</td>\n      <td>2014.0</td>\n      <td>Grenoble Alpes Métropole</td>\n      <td>Point</td>\n      <td>5.720047</td>\n      <td>45.190442</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 189
    }
   ],
   "source": [
    "trees.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "display dataframe columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Index(['ELEM_POINT_ID', 'CODE', 'SOUS_CATEGORIE', 'SOUS_CATEGORIE_DESC',\n       'CODE_PARENT', 'CODE_PARENT_DESC', 'ADR_SECTEUR', 'GENRE_BOTA',\n       'ESPECE', 'VARIETE', 'STADEDEDEVELOPPEMENT', 'ANNEEDEPLANTATION',\n       'COLLECTIVITE', 'type', 'longitude', 'latitude'],\n      dtype='object')"
     },
     "metadata": {},
     "execution_count": 190
    }
   ],
   "source": [
    "trees.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make train test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### random split\n",
    "\n",
    "In the following we want to build a machine learning model that helps us predict the plantation year for different trees based on their characteristics.\n",
    "\n",
    "For this you have to first remove the column `ANNEEDEPLANTATION` from the dataframe and save the result in the variable year. Hint: use `pop`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = trees.pop(\"ANNEEDEPLANTATION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the trees and the year data into train and test partitions. Use seed=800.\n",
    "\n",
    "You must save the result in 4 variables: `X_train` (instances in the train set), `X_test` (instances in the test set), `y_train` (labels corresponding to the instances in the train set), `y_test` (labels corresponding to the instances in the test set).\n",
    "\n",
    "For clarifications, read the `train_test_split` documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(trees,years,random_state=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many instances are there in the train set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(23550, 15)"
     },
     "metadata": {},
     "execution_count": 194
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many instances are there in the test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(7850, 15)"
     },
     "metadata": {},
     "execution_count": 195
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stratified shuffle - alternative (and very optional at this stage!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import  `StratifiedShuffleSplit` from scikit-learn package `model_selection`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `StratifiedShuffleSplit` instance with `n_split=1` and a `test_size=0.25`  and a `random_state=800`.\n",
    "\n",
    "Store this instance in a variable named `stratSplit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "stratSplit  = StratifiedShuffleSplit(n_splits=1,test_size=0.25,random_state=43)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `split` function of this `StratifiedShuffleSplit` instance.\n",
    "\n",
    "(*Hint the arguments of this function are avalaible in the [sklearn doc](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedShuffleSplit.html)* )\n",
    "\n",
    "Store the result of the `split` function in a variable named `splits`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = stratSplit.split(trees,years)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the type of the `splits` variable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "generator"
     },
     "metadata": {},
     "execution_count": 199
    }
   ],
   "source": [
    "type(splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `splits` variable for creating the test and train sets.\n",
    "\n",
    "The following cell must create the `X_train`, `X_test`, `y_train`  and `y_test` variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'train_index' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-200-f4fafa8f8c39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrees\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myears\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myears\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_index' is not defined"
     ]
    }
   ],
   "source": [
    "X_train,X_test = trees.iloc[train_index],trees.iloc[test_index]\n",
    "y_train,y_test = years.iloc[train_index],years.iloc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(23550, 15) (7850, 15)\n"
    }
   ],
   "source": [
    "print(X_train.shape,X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the the proportions we find look consistent between splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for checking proportions in labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for checking proportions in data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Statistics\n",
    "\n",
    "Should usually only be done after the split. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive model\n",
    "Used as a baseline model to know if our ML models are remotely useful. Here based on average tree age."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data - using pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting this step, check how one hot encoding works.\n",
    "\n",
    "Import the `StandardScaler` and `OneHotEncoder` from the scikit-learn `preprocessing` package.\n",
    "\n",
    "Import the `SimpleImputer` from the scikit-learn `impute` package.\n",
    "Finally import the `Pipeline` from the scikit-learn `pipeline` package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make pipelines for numerical and catageorical data\n",
    "\n",
    "Import the `TransformerMixin` and `BaseEstimator` from the scikit-learn `base` package.\n",
    "\n",
    "Import the `ColumnTransformer` from the scikit-learn `compose` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin,BaseEstimator\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the goal is to create a pipeline for each type of attribute\n",
    "\n",
    "The two lists in the code cell below contain the numerical and categorical attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_attribs = ['longitude', 'latitude']\n",
    "cat_attribs = [\"ADR_SECTEUR\", 'COLLECTIVITE', 'STADEDEDEVELOPPEMENT'] # adding , 'GENRE_BOTA' here create many more columns which might cause problems. Leaving out for now.\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create two pipelines which will use a `SimpleImputer` for completing missing data:\n",
    "\n",
    "- `num_pipeline` which process numerical data by scaling them using a `StandardScaler`.\n",
    "- `cat_pipeline` which process categorical data by encoding categories using a `OneHotEncoder`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFrameSelector(TransformerMixin,BaseEstimator):\n",
    "    def __init__(self,name_attributes):\n",
    "        self.name_attributes = name_attributes\n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self,X):\n",
    "        return X[self.name_attributes].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_pipeline = Pipeline([(\"DFS\",DataFrameSelector(num_attribs)),(\"SI\",SimpleImputer(strategy=\"median\")),(\"SS\",StandardScaler())])\n",
    "cat_pipeline = Pipeline([(\"DFS\",DataFrameSelector(cat_attribs)),(\"SI\",SimpleImputer(strategy='constant')),(\"OHE\",OneHotEncoder(handle_unknown='ignore'))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if pipelines creating expected shape for categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(23550, 12)"
     },
     "metadata": {},
     "execution_count": 209
    }
   ],
   "source": [
    "X_trainC = cat_pipeline.fit_transform(X_train,y_train)\n",
    "X_testC = cat_pipeline.fit_transform(X_train,y_train)\n",
    "\n",
    "X_trainC.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<23550x12 sparse matrix of type '<class 'numpy.float64'>'\n\twith 70650 stored elements in Compressed Sparse Row format>"
     },
     "metadata": {},
     "execution_count": 210
    }
   ],
   "source": [
    "X_trainC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if pipelines creating expected shape for numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(23550, 2)"
     },
     "metadata": {},
     "execution_count": 211
    }
   ],
   "source": [
    "X_trainN = num_pipeline.fit_transform(X_train,y_train)\n",
    "X_testN = num_pipeline.fit_transform(X_train,y_train)\n",
    "\n",
    "X_trainN.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform the data using full pipeline\n",
    "\n",
    "This step consists in combining the two pipelines into one named `full_pipeline`.\n",
    "\n",
    "Create a variable named `full_pipeline` and use a `ColumnTransformer` to create a pipeline combining the 2 created before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import `FeatureUnion` from the scikit-learn `pipeline` package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here\n",
    "full_pipeline = ColumnTransformer([(\"num\",num_pipeline,num_attribs),(\"cat\",cat_pipeline,cat_attribs)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use the full pipeline to `fit_transform` the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainT = full_pipeline.fit_transform(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the full pipeline to `fit_transform` the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_testT = full_pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the shape of both transformed set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(23550, 14)"
     },
     "metadata": {},
     "execution_count": 215
    }
   ],
   "source": [
    "X_trainT.shape # quick check for shape -> yes,  13 columns is what we expect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the same to test data, just to ensure that there are no problems pre-modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_testT = full_pipeline.transform(X_test) # TRANSFORM ONLY(!) test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New pipeline\n",
    "\n",
    "Now import `BaseEstimator` and `TransformerMixin` from the scikit-learn `base` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the `CombinedAttributesAdderNewVersion` class declared below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column index\n",
    "longitude_id, latitude_id = X_train.columns.get_loc(\"longitude\"),X_train.columns.get_loc(\"latitude\")\n",
    "# dataframe column indices for these cols\n",
    "\n",
    "class CombinedAttributesAdderNewVersion(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self): # no *args or **kargs\n",
    "        pass\n",
    "    def fit(self, X, y=None):\n",
    "        return self# return the object itself\n",
    "    def transform(self, X):\n",
    "        X = X.to_numpy()# convert the train set to numpy array\n",
    "        new_feature = X[:,0]+X[:,1]# combine the two attributes of the given dataframe\n",
    "        return pd.DataFrame(new_feature)\n",
    "        # return as dataframe created from the new_feature variable declared before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the `CombinedAttributesAdderNewVersion` and use the `fit_transform` method on the `LONGITUDE` and `LATITUDE` features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_adder = CombinedAttributesAdderNewVersion()# instance of CombinedAttributesAdderNewVersion\n",
    "X_train_new_att = attr_adder.fit_transform(X_train.loc[:,[\"longitude\",\"latitude\"]]) # fit_transform on the right columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "display the new attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "               0\n0      50.905736\n1      50.910903\n2      50.929723\n3      50.897548\n4      50.912131\n...          ...\n23545  50.918871\n23546  50.922004\n23547  50.927329\n23548  50.924552\n23549  50.893101\n\n[23550 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>50.905736</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>50.910903</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>50.929723</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>50.897548</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>50.912131</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>23545</th>\n      <td>50.918871</td>\n    </tr>\n    <tr>\n      <th>23546</th>\n      <td>50.922004</td>\n    </tr>\n    <tr>\n      <th>23547</th>\n      <td>50.927329</td>\n    </tr>\n    <tr>\n      <th>23548</th>\n      <td>50.924552</td>\n    </tr>\n    <tr>\n      <th>23549</th>\n      <td>50.893101</td>\n    </tr>\n  </tbody>\n</table>\n<p>23550 rows × 1 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 219
    }
   ],
   "source": [
    "X_train_new_att"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the pipelines created before and a new feature pipeline in order to create a full_pipeline which includes the newly created feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_attribs = ['longitude', 'latitude']\n",
    "cat_attribs = [\"ADR_SECTEUR\", 'COLLECTIVITE', 'STADEDEDEVELOPPEMENT']\n",
    "\n",
    "num_pipeline = num_pipeline #numerical features pipeline\n",
    "\n",
    "cat_pipeline = cat_pipeline #categorical features pipeline\n",
    "\n",
    "new_features = Pipeline([(\"features\",CombinedAttributesAdderNewVersion())]) # create the new feature using the CombinedAttributesAdderNewVersion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a full pipeline with the pipeline created before.\n",
    "\n",
    "This full pipeline has to create two new features : \n",
    "- the first combines the `LONGITUDE`and `LATITUDE` columns\n",
    "- the other combines the `LONGITUDE` and `ADR_SECTEUR` columns\n",
    "\n",
    "Complete the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "full_pipeline = ColumnTransformer([(\"num\",num_pipeline,num_attribs),(\"cat\",cat_pipeline,cat_attribs),((\"f1\"),new_features,num_attribs),(\"f2\",new_features,[\"longitude\",\"ADR_SECTEUR\"])]) # code here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `fit_transform` method of the new pipeline on the train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainT = full_pipeline.fit_transform(X_train,y_train) #code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the `X_trainT` by instanciating a dataframe with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "              0         1    2    3    4    5    6    7    8    9   10   11  \\\n0      0.590012 -0.507185  0.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0  1.0   \n1      0.982725 -0.497273  0.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0  1.0   \n2      0.968887  1.098621  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  0.0   \n3      0.655137 -1.265350  0.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  1.0  0.0   \n4      0.920956 -0.327421  0.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0   \n...         ...       ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n23545  1.298442 -0.168982  0.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  1.0   \n23546  1.515768 -0.140606  0.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0   \n23547  1.124375  0.729544  0.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  1.0  0.0   \n23548  0.255137  1.435226  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  0.0   \n23549 -0.762198 -0.107834  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  1.0  0.0   \n\n        12   13         14         15  \n0      0.0  0.0  50.905736  10.734914  \n1      0.0  0.0  50.910903  10.739964  \n2      0.0  0.0  50.929723   7.739786  \n3      0.0  0.0  50.897548  11.735751  \n4      0.0  0.0  50.912131  10.739170  \n...    ...  ...        ...        ...  \n23545  0.0  0.0  50.918871  10.744024  \n23546  0.0  0.0  50.922004  10.746818  \n23547  0.0  0.0  50.927329  10.741785  \n23548  0.0  0.0  50.924552   7.730608  \n23549  0.0  0.0  50.893101   9.717526  \n\n[23550 rows x 16 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n      <th>12</th>\n      <th>13</th>\n      <th>14</th>\n      <th>15</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.590012</td>\n      <td>-0.507185</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>50.905736</td>\n      <td>10.734914</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.982725</td>\n      <td>-0.497273</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>50.910903</td>\n      <td>10.739964</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.968887</td>\n      <td>1.098621</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>50.929723</td>\n      <td>7.739786</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.655137</td>\n      <td>-1.265350</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>50.897548</td>\n      <td>11.735751</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.920956</td>\n      <td>-0.327421</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>50.912131</td>\n      <td>10.739170</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>23545</th>\n      <td>1.298442</td>\n      <td>-0.168982</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>50.918871</td>\n      <td>10.744024</td>\n    </tr>\n    <tr>\n      <th>23546</th>\n      <td>1.515768</td>\n      <td>-0.140606</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>50.922004</td>\n      <td>10.746818</td>\n    </tr>\n    <tr>\n      <th>23547</th>\n      <td>1.124375</td>\n      <td>0.729544</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>50.927329</td>\n      <td>10.741785</td>\n    </tr>\n    <tr>\n      <th>23548</th>\n      <td>0.255137</td>\n      <td>1.435226</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>50.924552</td>\n      <td>7.730608</td>\n    </tr>\n    <tr>\n      <th>23549</th>\n      <td>-0.762198</td>\n      <td>-0.107834</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>50.893101</td>\n      <td>9.717526</td>\n    </tr>\n  </tbody>\n</table>\n<p>23550 rows × 16 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 223
    }
   ],
   "source": [
    "df = pd.DataFrame(X_trainT)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Build"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression\n",
    "\n",
    "Import the `LinearRegression` model from the scikit-learn `linear_model` package.\n",
    "\n",
    "Import `cross_val_score` from the scikit-learn `model_selection` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score as cvs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the LinearRegression object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build linear regresion model and estimate test error using cross validation (10 folds).\n",
    "\n",
    "Store the cross validation scores in a `scores` variable. \n",
    "\n",
    "*Use the Negative Mean Square Error ($NMSE$) as scoring metric.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg.fit(X_trainT,y_train)\n",
    "\n",
    "scores = cvs(lin_reg,X_trainT,y_train,scoring=\"neg_mean_squared_error\",cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "describe the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([-170.31411547, -176.98928496, -166.03339419, -169.41911681,\n       -177.47335573, -168.89577116, -171.47021972, -173.57999428,\n       -170.41281671, -175.47670399])"
     },
     "metadata": {},
     "execution_count": 227
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision tree regressor\n",
    "\n",
    "Now, import the `DecisionTreeRegressor` from the scikit-learn `tree` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a `DecisionTreeRegressor` with a random state equals to 42."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_tree = DecisionTreeRegressor(random_state=42).fit(X_trainT,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use the `cross_val_score` method to train and evaluate the built model, with the **NMSE** scoring metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_tree = cvs(dec_tree,X_trainT,y_train,scoring=\"neg_mean_squared_error\",cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([-75.25902335, -80.07388535, -84.78089172, -80.54140127,\n       -70.44543524, -74.16645435, -80.2552017 , -70.85350318,\n       -96.22377919, -74.02292994])"
     },
     "metadata": {},
     "execution_count": 237
    }
   ],
   "source": [
    "score_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### random forest - small number of trees\n",
    "\n",
    "Now, import the `RandomForestRegressor` from the scikit-learn `ensemble` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a `RandomForestRegressor` with 4 `estimators` and 8 `max_features`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_for_reg = RandomForestRegressor(n_estimators=4,max_features=8).fit(X_trainT,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use the `cross_val_score` method to train and evaluate the built model, with the **NMSE** scoring metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_rand_for = cvs(r_for_reg,X_trainT,y_train,scoring=\"neg_mean_squared_error\",cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([-56.75636943, -58.37489384, -63.7345276 , -57.49238323,\n       -54.21435775, -60.98357219, -52.95106157, -51.31135881,\n       -61.17940552, -58.58142251])"
     },
     "metadata": {},
     "execution_count": 241
    }
   ],
   "source": [
    "score_rand_for"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does these new features improve the model performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare to the previous "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}